{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%autosave 10\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style>\n",
    "\"\"\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from plotutils import plot_images_as_grid\n",
    "\n",
    "from imageprosessing import hist_match_images, enhance_motion_contrast, normalize_data\n",
    "from sharedvariables import get_video_sessions\n",
    "from video_session import VideoSession\n",
    "from imageprosessing import SessionPreprocessor\n",
    "from patchextraction import SessionPatchExtractor\n",
    "from patchextraction import SessionPatchExtractor as PE\n",
    "from cnnlearning import CNN\n",
    "\n",
    "from learningutils import ImageDataset\n",
    "from classificationutils import create_probability_map\n",
    "from plotutils import *\n",
    "from cnnlearning import TrainingTracker, train\n",
    "import os\n",
    "import collections\n",
    "import pathlib\n",
    "\n",
    "import scipy\n",
    "import skimage\n",
    "from skimage.morphology import binary_dilation as bd\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import copy\n",
    "\n",
    "from tqdm.contrib import tzip\n",
    "\n",
    "from patchextraction import extract_patches\n",
    "from patchextraction import SessionPatchExtractor as PE\n",
    "from imageprosessing import ImageRegistrator\n",
    "from collections import OrderedDict\n",
    "\n",
    "report_images_folder = os.path.join(\n",
    "    '/', 'home', 'tom', 'thesis-report', 'images',\n",
    "    'mc2-npp32-tp1-ps31-mt0-pr-false-uv-true-17'\n",
    ")\n",
    "pathlib.Path(report_images_folder).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# change this\n",
    "classifier_params = collections.OrderedDict(        \n",
    "    patch_size=31,\n",
    "    mixed_channels=True,\n",
    "    drop_confocal=True,\n",
    "\n",
    "    n_negatives_per_positive=32,\n",
    "    negative_extraction_mode=SessionPatchExtractor.CIRCLE,                             \n",
    "    use_vessel_mask=True\n",
    ")\n",
    "\n",
    "# load the correct models\n",
    "results = TrainingTracker.from_file('tmp-res/mc2-npp32-tp1-ps31-mt0-pr-false-uv-true-17/results.pkl')\n",
    "\n",
    "## ## ## ## ##\n",
    "balanced_accuracy = results.recorded_models['best_valid_balanced_accuracy']['valid_classification_results'].balanced_accuracy\n",
    "print('Model balanced acuracy', balanced_accuracy)\n",
    "\n",
    "video_sessions = get_video_sessions(marked=True, registered=False, validation=True)\n",
    "print('loaded Video sessions:', len(video_sessions))\n",
    "[vs.basename for vs in video_sessions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance on training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patch classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classificationutils import SessionClassifier\n",
    "\n",
    "video_sessions = get_video_sessions(marked=True, registered=True, validation=False)\n",
    "balanced_accuracy =\\\n",
    "results.recorded_models['best_train_balanced_accuracy']['train_classification_results'].balanced_accuracy\n",
    "model = results.recorded_models['best_train_balanced_accuracy']['model'].eval()\n",
    "\n",
    "print('General balanced accuracy', balanced_accuracy)\n",
    "for vs in video_sessions:\n",
    "    vs.load_vessel_masks()\n",
    "    vs_c = SessionClassifier(\n",
    "        vs, model, **classifier_params\n",
    "    )\n",
    "    \n",
    "    classification_results = vs_c.classify_cells()\n",
    "    print(vs.basename)\n",
    "    print(f'Sensitivity: {classification_results.positive_accuracy:.3f}', \n",
    "          f'Specificity: {classification_results.negative_accuracy:.3f}',\n",
    "          f'Balanced acc: {classification_results.balanced_accuracy:.3f}')\n",
    "    print('-----------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Position estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_sessions = get_video_sessions(marked=True, registered=True, validation=False)\n",
    "vs = video_sessions[3]\n",
    "vs.load_vessel_masks()\n",
    "\n",
    "frame_idx = vs.validation_frame_idx\n",
    "# vs.vessel_mask_oa790[300:, 400:] = 0\n",
    "# vs.vessel_mask_oa790[:, :175] = 0\n",
    "# vs.vessel_mask_oa790[:, 275:] = 0\n",
    "# vs.vessel_mask_oa790[500:, :] = 0 \n",
    "positions = vs.cell_positions[frame_idx]\n",
    "masked_frame = vs.frames_oa790[frame_idx] * vs.mask_frames_oa790[frame_idx] * vs.vessel_mask_oa790\n",
    "\n",
    "### plots ###\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.figure(figsize=(10, 10))\n",
    "# no_ticks()\n",
    "plt.imshow(masked_frame)\n",
    "plt.scatter(positions[:, 0], positions[:, 1], s=25)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs_c = SessionClassifier(vs, model, **classifier_params)\n",
    "estimated_locations = vs_c.estimate_locations(frame_idx, grid_search=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = vs_c.result_evaluations[frame_idx].n_true_positives \n",
    "FP = vs_c.result_evaluations[frame_idx].n_false_positives\n",
    "FN = vs_c.result_evaluations[frame_idx].n_false_negatives\n",
    "\n",
    "2 * TP / (2 * TP + FP + FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " len(estimated_locations)/ FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm = vs_c.probability_maps[frame_idx]\n",
    "pm = np.uint8(pm * 255)\n",
    "pm = cv2.applyColorMap(pm, cv2.COLORMAP_JET)\n",
    "pm = cv2.cvtColor(pm, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "from patchextraction import get_mask_bounds\n",
    "x_min, x_max, y_min, y_max = get_mask_bounds(vs.registered_mask_frames_oa850[frame_idx])\n",
    "pm = pm[y_min:y_max, x_min:x_max]\n",
    "import PIL.Image\n",
    "PIL.Image.fromarray(pm).save(f'/mnt/large/tom/{vs.basename}_prob_map.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['axes.titlesize'] = 45\n",
    "vs_c.result_evaluations[frame_idx].visualize()\n",
    "plt.savefig(f'/mnt/large/tom/{vs.basename}_evaluation_results.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance on validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on patch classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_video_sessions = get_video_sessions(marked=True, registered=True, validation=True)\n",
    "\n",
    "for vs in validation_video_sessions:\n",
    "    vs.load_vessel_masks()\n",
    "    vs.visualize_registration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classificationutils import SessionClassifier\n",
    "\n",
    "balanced_accuracy =\\\n",
    "results.recorded_models['best_valid_balanced_accuracy']['valid_classification_results'].balanced_accuracy\n",
    "model = results.recorded_models['best_valid_balanced_accuracy']['model'].eval()\n",
    "\n",
    "print('General balanced accuracy', balanced_accuracy)\n",
    "for vs in validation_video_sessions:\n",
    "    vs_c = SessionClassifier(vs, model, **classifier_params)\n",
    "    classification_results = vs_c.classify_cells()\n",
    "    print(vs.basename)\n",
    "    print(f'Sensitivity: {classification_results.positive_accuracy:.3f}', \n",
    "          f'Specificity: {classification_results.negative_accuracy:.3f}',\n",
    "          f'Balanced acc: {classification_results.balanced_accuracy:.3f}')\n",
    "    print('-----------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Position estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = validation_video_sessions[0]\n",
    "frame_idx = vs.validation_frame_idx\n",
    "\n",
    "positions = vs.cell_positions[frame_idx]\n",
    "masked_frame = vs.frames_oa790[frame_idx] * vs.vessel_mask_oa790 * vs.mask_frames_oa790[frame_idx]\n",
    "\n",
    "### plots #### \n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.figure(figsize=(10, 10))\n",
    "no_ticks()\n",
    "plt.imshow(masked_frame)\n",
    "plt.scatter(positions[:, 0], positions[:, 1], s=25)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = validation_video_sessions[0]\n",
    "vs_c = SessionClassifier(vs, model, **classifier_params)\n",
    "estimated_locations = vs_c.estimate_locations(frame_idx, grid_search=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['axes.titlesize'] = 50\n",
    "vs_c.result_evaluations[frame_idx].visualize()\n",
    "plt.savefig(f'/mnt/large/tom/{vs.basename}_valid_evaluation_results.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = vs_c.result_evaluations[vs.validation_frame_idx]\n",
    "s = evaluation.sigma\n",
    "H = evaluation.extended_maxima_h\n",
    "T = evaluation.region_max_threshold\n",
    "print(f's: {s:.3f}')\n",
    "print(f'H: {H:.3f}')\n",
    "print(f'T: {T:.3f}')\n",
    "from classificationutils import RegionCoordSelectMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_idx = vs.validation_frame_idx\n",
    "estimated_locations = vs_c.estimate_locations(\n",
    "    frame_idx, grid_search=False,\n",
    "    region_coord_select_mode=RegionCoordSelectMode.GEOMETRIC_CENTROID,\n",
    "    use_vessel_mask=False,\n",
    "    sigma=s, extended_maxima_h=H, region_max_threshold=T)\n",
    "vs_c.result_evaluations[frame_idx].visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_idx = vs.validation_frame_idx\n",
    "\n",
    "pm = vs_c.probability_maps[frame_idx]\n",
    "pm = np.uint8(pm * 255)\n",
    "pm = cv2.applyColorMap(pm, cv2.COLORMAP_JET)\n",
    "pm = cv2.cvtColor(pm, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "from patchextraction import get_mask_bounds\n",
    "import PIL.Image\n",
    "x_min, x_max, y_min, y_max = get_mask_bounds(vs.registered_mask_frames_oa850[frame_idx])\n",
    "pm = pm[y_min:y_max, x_min:x_max]\n",
    "\n",
    "PIL.Image.fromarray(pm).save(os.path.join(\n",
    "    report_images_folder, f'{vs.basename}no_vessel_mask_valid_prob_map.png'\n",
    "))\n",
    "PIL.Image.fromarray(pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_idx = vs.validation_frame_idx\n",
    "estimated_locations = vs_c.estimate_locations(\n",
    "    frame_idx, grid_search=False,\n",
    "    region_coord_select_mode=RegionCoordSelectMode.GEOMETRIC_CENTROID,\n",
    "    sigma=s, extended_maxima_h=H, region_max_threshold=T)\n",
    "vs_c.result_evaluations[frame_idx].visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_idx = vs.validation_frame_idx\n",
    "estimated_locations = vs_c.estimate_locations(\n",
    "    frame_idx, grid_search=False,\n",
    "    region_coord_select_mode=RegionCoordSelectMode.MAX_INTENSITY_PIXEL,\n",
    "    sigma=s, extended_maxima_h=H, region_max_threshold=T)\n",
    "vs_c.result_evaluations[frame_idx].visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_idx = vs.validation_frame_idx\n",
    "estimated_locations = vs_c.estimate_locations(\n",
    "    frame_idx, grid_search=False,\n",
    "    region_coord_select_mode=RegionCoordSelectMode.WEIGHTED_CENTROID,\n",
    "    sigma=s, extended_maxima_h=H, region_max_threshold=T)\n",
    "vs_c.result_evaluations[frame_idx].visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_idx = vs.validation_frame_idx\n",
    "\n",
    "pm = vs_c.probability_maps[frame_idx]\n",
    "pm = np.uint8(pm * 255)\n",
    "pm = cv2.applyColorMap(pm, cv2.COLORMAP_JET)\n",
    "pm = cv2.cvtColor(pm, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "from patchextraction import get_mask_bounds\n",
    "import PIL.Image\n",
    "x_min, x_max, y_min, y_max = get_mask_bounds(vs.registered_mask_frames_oa850[frame_idx])\n",
    "pm = pm[y_min:y_max, x_min:x_max]\n",
    "\n",
    "PIL.Image.fromarray(pm).save(os.path.join(\n",
    "    report_images_folder, f'{vs.basename}_valid_prob_map.png'\n",
    "))\n",
    "PIL.Image.fromarray(pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classificationutils import estimate_cell_positions_from_probability_map\n",
    "plt.rcParams['axes.titlesize'] = 45\n",
    "estimate_cell_positions_from_probability_map(vs_c.probability_maps[frame_idx],\n",
    "     sigma=s, extended_maxima_h=H, region_max_threshold=T,                                        \n",
    "     visualise_intermediate_results=True,)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame_idx in vs.cell_positions:\n",
    "    vs_c.estimate_locations(frame_idx, grid_search=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_coefficients = np.array([vs_c.result_evaluations[frame_idx].dice for frame_idx in vs.cell_positions])\n",
    "sigmas = np.array([vs_c.result_evaluations[frame_idx].sigma for frame_idx in vs.cell_positions])\n",
    "extended_maxima_hs = np.array([vs_c.result_evaluations[frame_idx].extended_maxima_h for frame_idx in vs.cell_positions])\n",
    "regmax_thresholds = np.array([vs_c.result_evaluations[frame_idx].region_max_threshold for frame_idx in vs.cell_positions])\n",
    "\n",
    "dice_mean = np.mean(dice_coefficients)\n",
    "s_mean = np.mean(sigmas)\n",
    "h_mean = np.mean(extended_maxima_hs)\n",
    "t_mean = np.mean(regmax_thresholds)\n",
    "print('Dice mean', dice_mean)\n",
    "print('Sigmas mean', s_mean)\n",
    "print('Extented maximas hs mean', h_mean)\n",
    "print('regmax_thresholds mean', t_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = validation_video_sessions[0]\n",
    "vs_c2 = SessionClassifier(vs, model, **classifier_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame_idx in vs.cell_positions:\n",
    "    vs_c2.estimate_locations(\n",
    "        frame_idx, grid_search=False,  \n",
    "        sigma=s_mean, extended_maxima_h=h_mean, region_max_threshold=t_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_coefficients = np.array([vs_c2.result_evaluations[frame_idx].dice for frame_idx in vs.cell_positions])\n",
    "sigmas = np.array([vs_c2.result_evaluations[frame_idx].sigma for frame_idx in vs.cell_positions])\n",
    "extended_maxima_hs = np.array([vs_c2.result_evaluations[frame_idx].extended_maxima_h for frame_idx in vs.cell_positions])\n",
    "regmax_thresholds = np.array([vs_c2.result_evaluations[frame_idx].region_max_threshold for frame_idx in vs.cell_positions])\n",
    "\n",
    "dice_mean = np.mean(dice_coefficients)\n",
    "s_mean = np.mean(sigmas)\n",
    "h_mean = np.mean(extended_maxima_hs)\n",
    "t_mean = np.mean(regmax_thresholds)\n",
    "print('Dice mean', dice_mean)\n",
    "print('Sigmas mean', s_mean)\n",
    "print('Extented maximas hs mean', h_mean)\n",
    "print('regmax_thresholds mean', t_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vs_c2.result_evaluations[frame_idx].visualize()\n",
    "# plt.savefig(os.path.join(\n",
    "#     f'/mnt/large/tom/{vs.basename}_evaluation_results.png'\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability map on validation videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = video_sessions[1]\n",
    "vs_c2 = SessionClassifier(vs, model, patch_size=21)\n",
    "frame_idx = list(vs.cell_positions.keys())[0]\n",
    "positions = vs.cell_positions[frame_idx]\n",
    "\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.figure(figsize=(10, 10))\n",
    "no_ticks()\n",
    "plt.imshow(vs.frames_oa790[0] * vs.vessel_mask_oa790 * vs.mask_frames_oa790[0])\n",
    "plt.scatter(positions[:, 0], positions[:, 1], s=25)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs_c2.estimate_locations(frame_idx, grid_search=True)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.figure(figsize=(10, 10))\n",
    "no_ticks()\n",
    "plt.imshow(vs_c2.probability_maps[frame_idx], cmap='hot')\n",
    "plt.scatter(positions[:, 0], positions[:, 1], s=25)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame_idx in vs.cell_positions:\n",
    "    vs_c2.estimate_locations(frame_idx, grid_search=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_coefficients = np.array([vs_c2.result_evalutations[frame_idx].dice for frame_idx in vs.cell_positions])\n",
    "sigmas = np.array([vs_c2.result_evalutations[frame_idx].sigma for frame_idx in vs.cell_positions])\n",
    "extended_maxima_hs = np.array([vs_c2.result_evalutations[frame_idx].extended_maxima_h for frame_idx in vs.cell_positions])\n",
    "regmax_thresholds = np.array([vs_c2.result_evalutations[frame_idx].region_max_threshold for frame_idx in vs.cell_positions])\n",
    "print('Dice mean', np.mean(dice_coefficients))\n",
    "print('Sigmas mean', np.mean(sigmas))\n",
    "print('Extented maximas hs mean', np.mean(extended_maxima_hs))\n",
    "print('regmax_thresholds mean', np.mean(regmax_thresholds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs_c2.result_evalutations[frame_idx].visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.figure(figsize=(10, 10))\n",
    "no_ticks()\n",
    "plt.imshow(vs_c.probability_maps[0], cmap='hot')\n",
    "plt.scatter(positions[:, 0], positions[:, 1], s=25)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs_c2.save(os.path.join(pathlib.Path(results_path).parent, 'classification-2.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs_c2.__name__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
