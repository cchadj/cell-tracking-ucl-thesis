{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter Notebook settings\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "%autosave 1\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Plotting settings\n",
    "import matplotlib.pyplot as plt\n",
    "size=15\n",
    "params = {'legend.fontsize': 'large',\n",
    "          'figure.figsize': (20,8),\n",
    "          'axes.labelsize': size,\n",
    "          'axes.titlesize': size,\n",
    "          'xtick.labelsize': size*0.75,\n",
    "          'ytick.labelsize': size*0.75,\n",
    "          'axes.titlepad': 5}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "from cnnlearning import *\n",
    "from learningutils import *\n",
    "from patchextraction import *\n",
    "from imageprosessing import *\n",
    "from nearest_neighbors import *\n",
    "from evaluation import *\n",
    "from classificationutils import *\n",
    "from sharedvariables import *\n",
    "from vesseldetection import *\n",
    "from generate_datasets import *\n",
    "from train_model import load_model_from_cache, train_model_demo\n",
    "from plotutils import plot_images_as_grid\n",
    "from sharedvariables import get_video_sessions\n",
    "\n",
    "import os\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "patch_size=(21, 21)\n",
    "do_hist_match=True\n",
    "n_negatives_per_positive=3\n",
    "\n",
    "overwrite_cache=False\n",
    "verbose=True\n",
    "very_verbose=True\n",
    "\n",
    "### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ###\n",
    "trainset, validset,\\\n",
    "cell_images, non_cell_images,\\\n",
    "cell_images_marked, non_cell_images_marked, hist_match_template =\\\n",
    "get_cell_and_no_cell_patches(\n",
    "    patch_size=patch_size,\n",
    "    n_negatives_per_positive=n_negatives_per_positive,\n",
    "    do_hist_match=do_hist_match,\n",
    "    overwrite_cache=overwrite_cache,\n",
    "    v=verbose,\n",
    "    vv=very_verbose,\n",
    ")\n",
    "\n",
    "print(\"Cell images:\", cell_images.shape)\n",
    "print(\"Non cell images\", non_cell_images.shape)\n",
    "\n",
    "fig, axes = plt.subplots(4, 6, figsize=(20, 10))\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    ax.tick_params(\n",
    "        axis='both',\n",
    "        which='both',\n",
    "        left=False,       \n",
    "        right=False,\n",
    "        labelleft=False,\n",
    "        bottom=False,\n",
    "        top=False,\n",
    "        labelbottom=False)\n",
    "\n",
    "plt.rcParams['axes.titlesize'] = 15\n",
    "for i, ax in enumerate(axes[0, :]):\n",
    "    ax.imshow(cell_images[i], cmap='gray')\n",
    "    ax.set_title('Cell Image')\n",
    "    \n",
    "\n",
    "for i, ax in enumerate(axes[1, :]):\n",
    "    axes[1, i].imshow(cell_images_marked[i], cmap='gray')\n",
    "    ax.set_title('Cell Image marked')\n",
    "\n",
    "for i, ax in enumerate(axes[2, :]):\n",
    "    ax.imshow(non_cell_images[i], cmap='gray')\n",
    "    ax.set_title('Non Cell Image')\n",
    "    \n",
    "for i, ax in enumerate(axes[3, :]):\n",
    "    ax.imshow(non_cell_images_marked[i], cmap='gray')\n",
    "    ax.set_title('Non Cell image marked')\n",
    "    \n",
    "if do_hist_match:\n",
    "    plt.figure()\n",
    "    plt.imshow(hist_match_template, cmap='gray')\n",
    "    plt.title('Histogram matching template')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Create classifier model\n",
    "Either load model from cache or train a new one.\n",
    "\n",
    "**You can interrupt**, or Ctr - C at any time to stop training and get the best model at the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "load_model_from_cache = False\n",
    "\n",
    "train_params = collections.OrderedDict(\n",
    "    epochs=4000,\n",
    "    # lr = .001,\n",
    "    # optimizer=torch.optim.SGD(model.parameters(), lr=.001, weight_decay=5e-5, momentum=0.9),\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=.001, weight_decay=5e-4),\n",
    "    batch_size=1024 * 7,\n",
    "    do_early_stop=True,  # Optional default True\n",
    "    early_stop_patience=80,\n",
    "    learning_rate_scheduler_patience=100,\n",
    "    shuffle=True,\n",
    "    # valid_untrunsformed_normals = valid_untrunsformed_normals,\n",
    "    trainset=trainset,\n",
    "    validset=validset)\n",
    "\n",
    "### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ###\n",
    "model = train_model_demo(patch_size=patch_size,\n",
    "                         do_hist_match=do_hist_match, \n",
    "                         n_negatives_per_positive=n_negatives_per_positive,\n",
    "                         load_from_cache=load_model_from_cache,\n",
    "                         train_params=train_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation\n",
    "## Evaluation on a sample frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load sample frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 3\n",
    "video_file = unmarked_labeled_video_OA790_filenames[idx]\n",
    "csv_file = csv_cell_cords_OA790_filenames[idx]\n",
    "std_image = std_confocal_images_for_labeled_OA790[idx]\n",
    "\n",
    "assert files_of_same_source(video_file, csv_file)\n",
    "video_file, csv_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = get_frames_from_video(video_file)[..., 0]\n",
    "\n",
    "#### #### #### #### #### #### #### #### #### #### #### #### #### #### #### #### ####\n",
    "ground_truth_positions = get_positions_from_csv(csv_file, 1)\n",
    "sample_frame = frames[0, ...].astype(np.float32) / 255\n",
    "\n",
    "if do_hist_match:\n",
    "    sample_frame = np.float32(hist_match(sample_frame, template))\n",
    "\n",
    "print('Frames shape', frames.shape)\n",
    "print('Sample frame', sample_frame.shape)\n",
    "print('Blood cell positions for all frames', all_video_cell_coords.shape)\n",
    "print()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "axes[0].imshow(sample_frame, cmap='gray')\n",
    "axes[0].scatter(ground_truth_positions[:, 0], ground_truth_positions[:, 1], label='Manual positions')\n",
    "axes[0].set_title('Sample frame')\n",
    "axes[0].legend()\n",
    "\n",
    "vessel_image = plt.imread(std_image)\n",
    "axes[1].imshow(vessel_image, cmap='gray')\n",
    "axes[1].scatter(ground_truth_positions[:, 0], ground_truth_positions[:, 1], label='Manual positions')\n",
    "axes[1].set_title('Vessel standard deviation image')\n",
    "axes[1].legend()\n",
    "\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig_size = fig.get_size_inches()\n",
    "fig.set_size_inches((fig_size[0] * 3, fig_size[1] * 3))\n",
    "\n",
    "sample_frame_cell_patches = extract_patches_at_positions(sample_frame, ground_truth_positions, patch_size=patch_size)\n",
    "\n",
    "rxs, rys = get_random_point_on_rectangle(ground_truth_positions[:, 0], \n",
    "                                         ground_truth_positions[:, 1], \n",
    "                                         patch_size)\n",
    "\n",
    "non_cell_positions = np.array([rxs, rys]).T\n",
    "remove_positions_too_close_to_border_indices = get_positions_too_close_to_border(non_cell_positions,\n",
    "                                                                                 image_shape=sample_frame.shape[:2], \n",
    "                                                                                 patch_size=patch_size)\n",
    "non_cell_positions_new = np.delete(non_cell_positions, \n",
    "                                   remove_positions_too_close_to_border_indices,\n",
    "                                   axis=0)\n",
    "\n",
    "sample_frame_non_cell_patches = extract_patches_at_positions(sample_frame, \n",
    "                                                             non_cell_positions_new,\n",
    "                                                             patch_size=patch_size)\n",
    "\n",
    "print(sample_frame_cell_patches.shape)\n",
    "print('Positive accuracy on cells from sample frame:\\t\\t',\n",
    "     f'{classify_images(sample_frame_cell_patches, model).sum().item() / len(sample_frame_cell_patches):.3f}')\n",
    "print('Negative accuracy on non cells from sample frame:\\t',\n",
    "     f'{(1 - classify_images(sample_frame_non_cell_patches, model)).sum().item() / len(sample_frame_non_cell_patches):.3f}')\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create vessel mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vesseldetection import create_vessel_mask\n",
    "\n",
    "vessel_image_bordered = cv2.copyMakeBorder(vessel_image, *patch_size, *patch_size, cv2.BORDER_REFLECT)\n",
    "        \n",
    "vessel_mask = create_vessel_mask(vessel_image_bordered,\n",
    "                                 opening_kernel_size=3,\n",
    "                                 n_iterations=4,\n",
    "                                 visualise_intermediate_steps=True)\n",
    "vessel_mask = vessel_mask[patch_size[0]:(vessel_mask.shape[0] - patch_size[0]) ,\n",
    "                          patch_size[1]:(vessel_mask.shape[1] - patch_size[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(vessel_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate probability map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def create_probability_map(image,\n",
    "                           model,\n",
    "                           patch_size=(21, 21),\n",
    "                           padding=cv2.BORDER_REPLICATE,\n",
    "                           device='cuda',\n",
    "                           mask=None,\n",
    "                           ):\n",
    "    if len(image.shape) == 2:\n",
    "        # Add channel at end if grayscale. HxW -> HxWx1\n",
    "        image = image[:, :, np.newaxis]\n",
    "\n",
    "    # print('Image shape', image.shape)\n",
    "    # if mask is not None then create patches for every pixel.\n",
    "    if mask is None:\n",
    "        mask = np.ones(image.shape[:2], dtype=np.bool)\n",
    "\n",
    "\n",
    "    model = model.eval()\n",
    "    model = model.to(device)\n",
    "\n",
    "    # print('Mask shape', mask.shape)\n",
    "    # flatten mask to get indices to index patches\n",
    "    mask_flattened = mask.reshape(-1)\n",
    "    vessel_pixel_indices = np.where(mask_flattened)[0]\n",
    "\n",
    "    patches = extract_patches(image, patch_size, padding=padding)[vessel_pixel_indices]\n",
    "    label_probabilities = label_probability(patches, model, device)\n",
    "\n",
    "    probability_map = np.zeros(image.shape[:2], dtype=np.float32)\n",
    "    rows, cols = np.unravel_index(vessel_pixel_indices, probability_map.shape[:2])\n",
    "    probability_map[rows, cols] = label_probabilities[:, 1]\n",
    "\n",
    "    return probability_map\n",
    "\n",
    "\n",
    "probability_map = create_probability_map(sample_frame,\n",
    "                                         model,\n",
    "                                         mask=None,\n",
    "                                         patch_size=patch_size,\n",
    "                                         device=device)\n",
    "plt.imshow(probability_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate positions from probability map\n",
    "\n",
    "* First calculate the best $σ$ for the gaussian blur and the best $H$ for the extended maxima, maximising Dice's coefficient\n",
    "* Using the best $σ$ and $Η$ find the positions by binarising the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm = np.uint8(probability_map * 255)\n",
    "plt.imshow(pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_blurred = mh.gaussian_filter(pm, 3)\n",
    "\n",
    "plt.imshow(pm_blurred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_sigmas = np.arange(0.125, 3.25, 0.25)\n",
    "for s in gauss_sigmas:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "probability_map = pm\n",
    "pathlib.Path(CACHED_DICE).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "filename = os.path.join(CACHED_DICE, \n",
    "                        f'blood_cell_dices_coefficient_sigma_h_{patch_size[0]}_hm_{str(do_hist_match).lower()}.csv')\n",
    "try:\n",
    "    print(f'Loading dices coefficient and correspoding sigmas and hs from:\\n {filename}')\n",
    "    df = pd.read_csv(filename, usecols=(1, 2, 3))\n",
    "    print('Done')\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found. Finding sigma and h that maximise Dice's coefficient...\")\n",
    "    pd.set_option('display.max_rows', 20)\n",
    "    dices_coefficients = []\n",
    "    sigmas = []\n",
    "    Hs = []\n",
    "\n",
    "    gauss_sigmas = np.arange(0.125, 3.25, 0.25).astype(np.float32)\n",
    "    extended_maxima_Hs = np.arange(0, 255, 1).astype(np.uint8)\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    max_dices_coeff = 0\n",
    "    best_sigma = gauss_sigmas[0]\n",
    "    best_H = extended_maxima_Hs[0]\n",
    "    c = 0\n",
    "    for s in tqdm(gauss_sigmas):\n",
    "        for h in extended_maxima_Hs:\n",
    "            estimated_positions = get_cell_positions_from_probability_map(probability_map, s, h)\n",
    "\n",
    "            dices_coeff, _, _ = evaluate_results(ground_truth_positions, \n",
    "                                                 estimated_positions,\n",
    "                                                 sample_frame,\n",
    "                                                 patch_size=(19, 19))\n",
    "            if dices_coeff < 0:\n",
    "                continue\n",
    "            if dices_coeff > max_dices_coeff:\n",
    "                max_dices_coeff = dices_coeff\n",
    "                best_sigma = s\n",
    "                best_H = h\n",
    "\n",
    "            dices_coefficients.append(dices_coeff)\n",
    "            sigmas.append(s)\n",
    "            Hs.append(h)\n",
    "            \n",
    "\n",
    "            df = pd.DataFrame()\n",
    "            df['dices_coefficient'] = dices_coefficients\n",
    "            df['sigma'] = sigmas\n",
    "            df['extended_maxima_h'] = Hs\n",
    "            if c % 50 == 0;\n",
    "                print('progress is being made')\n",
    "#             if c % 30 == 0:\n",
    "#                 clear_output()\n",
    "#                 display(df)\n",
    "            c += 1\n",
    "            \n",
    "    print(f'Saving results to {filename}')\n",
    "    df.to_csv(filename)\n",
    "    print('Done')\n",
    "    \n",
    "pd.set_option('display.max_rows', 3)\n",
    "display(df)\n",
    "\n",
    "max_dices_coeff_idx = df['dices_coefficient'].argmax()\n",
    "\n",
    "print(\"Maximum Dice's coefficient values:\\n\")\n",
    "print(df.iloc[max_dices_coeff_idx])\n",
    "best_dices_coefficient = df.loc[max_dices_coeff_idx, 'dices_coefficient']\n",
    "best_sigma = df.loc[max_dices_coeff_idx, 'sigma']\n",
    "best_h = df.loc[max_dices_coeff_idx, 'extended_maxima_h']\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(probability_map)\n",
    "plt.scatter(ground_truth_positions[:, 0], ground_truth_positions[:, 1], c='red', s=8)\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig_size = fig.get_size_inches()\n",
    "fig.set_size_inches((fig_size[0] * 2,\n",
    "                     fig_size[1] * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 0.4\n",
    "seed = image - h\n",
    "dilated = reconstruction(seed, mask, method='dilation')\n",
    "hdome = image - dilated\n",
    "fig, (ax0, ax1, ax2) = plt.subplots(nrows=1, ncols=3, figsize=(8, 2.5))\n",
    "yslice = 197\n",
    "\n",
    "ax0.plot(mask[yslice], '0.5', label='mask')\n",
    "ax0.plot(seed[yslice], 'k', label='seed')\n",
    "ax0.plot(dilated[yslice], 'r', label='dilated')\n",
    "ax0.set_ylim(-0.2, 2)\n",
    "ax0.set_title('image slice')\n",
    "ax0.set_xticks([])\n",
    "ax0.legend()\n",
    "\n",
    "ax1.imshow(dilated, vmin=image.min(), vmax=image.max(), cmap='gray')\n",
    "ax1.axhline(yslice, color='r', alpha=0.4)\n",
    "ax1.set_title('dilated')\n",
    "ax1.axis('off')\n",
    "\n",
    "ax2.imshow(hdome, cmap='gray')\n",
    "ax2.axhline(yslice, color='r', alpha=0.4)\n",
    "ax2.set_title('image - dilated')\n",
    "ax2.axis('off')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imhmax_res = imhmaxima(prob_map_uint, 125)\n",
    "Image.fromarray(imhmax_res).save('imhmaxima_result.png')\n",
    "plt.imshow(imhmax_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_maxima_result = mh.regmax(imhmax_res, Bc=np.ones((3, 3), dtype=np.bool8))\n",
    "plt.imshow(extended_maxima_result)\n",
    "Image.fromarray(extended_maxima_result.astype(np.uint8)).save('extended_maxima_result.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imextendedmax(prob_map_uint, 125))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imextendedmax(prob_map_uint, 125))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(prob_map_uint).save('prob_map_uint.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(extrema.h_maxima(pm_sm, 125, structel)).save('tmp.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?extrema.h_maxima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(pm_sm).save('pm_sm.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structel = np.ones([3, 3], dtype=np.bool8)\n",
    "plt.imshow(extrema.h_maxima(prob_map_uint, 125, structel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imextendedmax(probability_map, 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_extended_max_bw = imextendedmax(probability_map, extended_maxima_H)\n",
    "\n",
    "labeled, nr_objects = mh.label(pm_extended_max_bw)\n",
    "\n",
    "# print(np.where(pm_extended_max_bw)[0])\n",
    "pm_extended_max = probability_map.copy()\n",
    "pm_extended_max[pm_extended_max_bw] = 0\n",
    "\n",
    "labeled, nr_objects = mh.label(pm_extended_max)\n",
    "predicted_cell_positions = mh.center_of_mass(probability_map, labeled)[:, [1, 0]]\n",
    "\n",
    "\n",
    "plt.imshow(pm_extended_max_bw)\n",
    "plt.scatter(predicted_cell_positions[:, 0], predicted_cell_positions[:, 1], c='red', s=8)\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig_size = fig.get_size_inches()\n",
    "fig.set_size_inches((fig_size[0] * 2,\n",
    "                     fig_size[1] * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(probability_map)\n",
    "plt.scatter(estimated_positions[:, 0], estimated_positions[:, 1], c='red', s=8)\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig_size = fig.get_size_inches()\n",
    "fig.set_size_inches((fig_size[0] * 2,\n",
    "                     fig_size[1] * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(np.where(pm_extended_max_bw)[0])\n",
    "pm_extended_max = probability_map.copy()\n",
    "pm_extended_max[pm_extended_max_bw] = 0\n",
    "\n",
    "# print(pm_extended_max)\n",
    "# Notice, the positions from the csv is x,y. The result from the probability is y,x so we swap.\n",
    "predicted_cell_positions = mh.center_of_mass(pm_extended_max_bw, labeled)[:, [1, 0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_sigma = best_sigma\n",
    "extended_maxima_H = best_h\n",
    "\n",
    "estimated_positions = get_cell_positions_from_probability_map(probability_map, \n",
    "                                                              gauss_sigma,\n",
    "                                                              extended_maxima_H,\n",
    "                                                              visualise_intermediate_results=True)\n",
    "\n",
    "dices_coeff, _, _ = evaluate_results(ground_truth_positions, \n",
    "                                     estimated_positions,\n",
    "                                     sample_frame,\n",
    "                                     patch_size=patch_size)\n",
    "plt.figure()\n",
    "# print(estimated_positions)\n",
    "plt.title(f\"Dice's coefficient {dices_coeff:.3f}\")\n",
    "plt.imshow(sample_frame, cmap='gray')\n",
    "plt.scatter(ground_truth_positions[:, 0], ground_truth_positions[:, 1],  s=51, label='Ground truth positions')\n",
    "plt.scatter(estimated_positions[:, 0], estimated_positions[:, 1], s=51, label='Estimated positions')\n",
    "plt.legend()\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig_size = fig.get_size_inches()\n",
    "fig.set_size_inches((fig_size[0] * 2,\n",
    "                     fig_size[1] * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Veselness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(registered_videos_2_stdev_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(registered_videos_2_stdev_images[11])\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_videos_2_stdev_images[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = plt.imread(registered_videos_2_stdev_images[11])\n",
    "f = np.fft.fft2(img)\n",
    "fshift = np.fft.fftshift(f)\n",
    "magnitude_spectrum = 20*np.log(np.abs(fshift))\n",
    "\n",
    "fshift_filtered = fshift.copy()\n",
    "fshift_filtered[250:275, ...] = 0.001\n",
    "magnitude_spectrum_filtered = 20*np.log(np.abs(fshift_filtered))\n",
    "# shift back (we shifted the center before)\n",
    "f_ishift = np.fft.ifftshift(fshift_filtered)\n",
    "# inverse fft to get the image back \n",
    "img_back = np.abs(np.fft.ifft2(f_ishift))\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(50, 50))\n",
    "axes[0].imshow(img, cmap = 'gray')\n",
    "axes[0].set_title('Input Image'), plt.xticks([]), plt.yticks([])\n",
    "axes[1].imshow(magnitude_spectrum, cmap = 'gray')\n",
    "axes[1].set_title('Magnitude Spectrum'), plt.xticks([]), plt.yticks([])\n",
    "axes[2].imshow(magnitude_spectrum_filtered, cmap='gray')\n",
    "axes[2].set_title('Magnitude Spectrum filtered'), plt.xticks([]), plt.yticks([])\n",
    "axes[3].imshow(img_back, cmap='gray')\n",
    "axes[3].set_title('Recovered Image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageEnhance\n",
    "from skimage import exposure\n",
    "plt.imshow(exposure.equalize_hist(img_back), cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_videos_2_stdev_images[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 6\n",
    "video_filename = registered_videos_2_filenames[idx]\n",
    "mask_filename = registered_videos_2_mask_filenames[idx]\n",
    "\n",
    "frames = get_frames_from_video(video_filename, normalise=False)[..., 0]\n",
    "masks  = np.bool8(get_frames_from_video(mask_filename, normalise=False))[..., 0]\n",
    "\n",
    "avg_img, std_img = create_average_and_stdev_image(frames, masks)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(45, 45))\n",
    "axes[0].imshow(avg_img, cmap='gray')\n",
    "axes[1].imshow(std_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_img.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(6, 4, figsize=(45, 45))\n",
    "vessel_images_all = []\n",
    "\n",
    "n_skip = 0\n",
    "skip_count = 0\n",
    "i = 0\n",
    "for row in range(axes.shape[0]):\n",
    "    for  col in range(axes.shape[1]):\n",
    "        if skip_count < n_skip:\n",
    "            skip_count += 1\n",
    "            i += 1\n",
    "            continue\n",
    "            \n",
    "        im = plt.imread(registered_videos_2_stdev_images[i])\n",
    "        # print(im.shape)\n",
    "        axes[row, col].imshow(im, cmap='gray')\n",
    "        axes[row, col].set_title(f'{im.shape} {i}')\n",
    "        vessel_images_all.append(im)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vessel_images_to_keep_indices = [0, 3, 6, 9, 12, 15, 21]\n",
    "vessel_images = [vessel_images_all[idx] for idx in vessel_images_to_keep_indices]\n",
    "print(len(vessel_images))\n",
    "\n",
    "fig, axes = plt.subplots(1, len(vessel_images), figsize=(45, 45))\n",
    "\n",
    "max_intensity = 0\n",
    "for ax, im in zip(axes, vessel_images):\n",
    "    ax.imshow(im, cmap='gray')\n",
    "    if max_intensity < im.max():\n",
    "        max_intensity = im.max()\n",
    "max_intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vessel_images_normalised = [\n",
    "    cv2.normalize(im, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX) for im in vessel_images\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.filters\n",
    "\n",
    "n_remove_border = 100\n",
    "sample_vessel_image = vessel_images_normalised[6].copy()\n",
    "sample_vessel_image = np.uint8(sample_vessel_image)\n",
    "sample_vessel_image = sample_vessel_image[n_remove_border: sample_vessel_image.shape[0] - n_remove_border,\n",
    "                                          n_remove_border: sample_vessel_image.shape[1] - n_remove_border]\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 6, figsize=(60, 60))\n",
    "axes[0].imshow(sample_vessel_image, cmap='gray')\n",
    "\n",
    "\n",
    "# sample_vessel_image_blurred = skimage.filters.median(sample_vessel_image,  mode='nearest', cval=0)\n",
    "sample_vessel_image_blurred = sample_vessel_image\n",
    "# sample_vessel_image_blurred = skimage.filters.gaussian(sample_vessel_image_blurred, sigma=3)\n",
    "frangi_image = skimage.filters.frangi(sample_vessel_image_blurred, alpha=.5, beta=.5, black_ridges=False)\n",
    "frangi_image_normalised = cv2.normalize(frangi_image, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)\n",
    "\n",
    "minLineLength = 1\n",
    "maxLineGap = 150\n",
    "\n",
    "binary_threshold = skimage.filters.threshold_otsu(frangi_image_normalised, nbins=256)\n",
    "BW = np.zeros_like(frangi_image_normalised)\n",
    "BW[frangi_image_normalised > binary_threshold * 0.5] = 1\n",
    "BW = np.uint8(BW)\n",
    "\n",
    "# lines = cv2.HoughLinesP(BW, 1, np.pi/180, 25, minLineLength=10, maxLineGap=300)\n",
    "# for line in lines:\n",
    "#     x1, y1, x2, y2 = line[0]\n",
    "#     cv2.line(BW, (x1, y1), (x2, y2), (255, 0, 0), 3)\n",
    "# BW = skimage.morphology.binary_dilation(BW)\n",
    "\n",
    "kernel = np.ones((13, 13),np.uint8)\n",
    "# closing = cv2.morphologyEx(BW, cv2.MORPH_CLOSE, kernel)\n",
    "dilation = cv2.dilate(BW, kernel, iterations=1)\n",
    "kernel = np.ones((7, 7),np.uint8)\n",
    "errosion = cv2.erode(dilation, kernel, iterations=2)\n",
    "\n",
    "axes[1].imshow(sample_vessel_image_blurred, cmap='gray')\n",
    "axes[2].imshow(frangi_image)\n",
    "axes[3].imshow(BW)\n",
    "axes[4].imshow(dilation)\n",
    "axes[5].imshow(errosion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skimage.filters.try_all_threshold(frangi_image, figsize=(18, 15), verbose=True)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?cv2.HoughLinesP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_remove_border = 100\n",
    "frangi_image = frangi_image[n_remove_border:frangi_image.shape[0] - n_remove_border, \n",
    "                            n_remove_border:frangi_image.shape[1] - n_remove_border]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frangi_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frangi_image.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_stdev_image_orig = plt.imread(registered_videos_stdev_images[0])\n",
    "sample_stdev_image = np.float32(sample_stdev_image_orig) / sample_stdev_image_orig.max()\n",
    "sample_stdev_image = np.uint8(sample_stdev_image * 255)\n",
    "print(sample_stdev_image.shape) \n",
    "plt.imshow(sample_stdev_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_stdev_image_orig[98, 98]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_stdev_image_recovered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_stdev_image_recovered = np.float32(sample_stdev_image) / 255\n",
    "plt.imshow(sample_stdev_image_recovered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test offset of x and y  in registered videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_video_filename = registered_videos_filenames[0]\n",
    "registered_video_csv = registered_videos_registration_csv[0]\n",
    "print(registered_video_filename, registered_video_csv, sep='\\n')\n",
    "frames = get_frames_from_video(registered_videos_filenames[0])\n",
    "csv_df = pd.read_csv(registered_video_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib notebook\n",
    "\n",
    "import matplotlib.animation\n",
    "\n",
    "xshifts = csv_df[' XShift']\n",
    "yshifts = csv_df[' YShift']\n",
    "\n",
    "def update(i):\n",
    "    print(i)\n",
    "    xshift = xshifts[i]\n",
    "    yshift = yshifts[i]\n",
    "\n",
    "    x = frames[i, ...]\n",
    "    ax.imshow(x, extent=[-x.shape[1]/2., x.shape[1]/2., -x.shape[0]/2., x.shape[0]/2. ])\n",
    "    ax.scatter(-xshift, yshift)\n",
    "\n",
    "    \n",
    "fig, ax = plt.subplots(1, 1, figsize=(25, 25))\n",
    "\n",
    "ani = matplotlib.animation.FuncAnimation(fig, \n",
    "                                         update,\n",
    "                                         frames=len(frames),\n",
    "                                         interval=1000, repeat=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.animation\n",
    "\n",
    "xshifts = csv_df[' XShift']\n",
    "yshifts = csv_df[' YShift']\n",
    "\n",
    "plt.sub\n",
    "plt.show()\n",
    "def update(i):\n",
    "    print(i)\n",
    "    xshift = xshifts[i]\n",
    "    yshift = yshifts[i]\n",
    "\n",
    "    x = frames[i, ...]\n",
    "    plt.imshow(x, extent=[-x.shape[1]/2., x.shape[1]/2., -x.shape[0]/2., x.shape[0]/2. ])\n",
    "    plt.scatter(xshift, yshift)\n",
    "\n",
    "        \n",
    "update(29)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0, len(frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESC = 27\n",
    "def draw_circle(event,x,y,flags,param):\n",
    "    # x grows from left to right\n",
    "    # y grows from top to bottom\n",
    "    global mouseX,mouseY\n",
    "    if event == cv2.EVENT_LBUTTONDBLCLK:\n",
    "        cv2.circle(im,(x,y),100,(255,0,0),-1)\n",
    "        mouseX, mouseY = x,y\n",
    "        print(x, y)\n",
    "\n",
    "\n",
    "im = plt.imread(registered_videos_stdev_images[0])\n",
    "\n",
    "cv2.namedWindow('image')\n",
    "cv2.imshow('image', im)\n",
    "cv2.setMouseCallback('image',draw_circle)\n",
    "\n",
    "while(1):\n",
    "    cv2.imshow('image', im)\n",
    "\n",
    "    #cv2.imshow('image',img)\n",
    "    k = cv2.waitKey(20) & 0xFF\n",
    "    if k == ESC or k == ord('q'):\n",
    "        break\n",
    "    elif k == ord('p'):\n",
    "        print(mouseX,mouseY)\n",
    "    else:\n",
    "        clear_output()\n",
    "        #print(k)\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('image', im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread(registered_videos_stdev_images[0])\n",
    "  \n",
    "\n",
    "cv2.imshow('ok', im)    \n",
    "cv2.waitKey()  \n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ginput(3)\n",
    "plt.imshow(im)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  How to evaluate segmentation results\n",
    "\n",
    "1- Dice score: which is 2 times the intersection between your segmentation results with the ground truth (manual segmentation) divided by the sumof both of them\n",
    "D= 2 (A intersect B) / (A + B) \n",
    "2- Jaccard similarity: which is the ratio between the intersection and union of the segmented results and the ground truth\n",
    "J= (A intersect B) / (A union B) \n",
    "Hint: there is one relation between J and D that you can easily derive."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
